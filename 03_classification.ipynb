{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EaqMKihE_SXR"
      },
      "source": [
        "# ML Lab 3 Tasks\n",
        "<table align=\"left\">\n",
        "  <td>\n",
        "    <a href=\"https://colab.research.google.com/github/marcinsawinski/UEP_KIE_ML_CLASS/blob/main/03_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXOyE3SX_SXR"
      },
      "source": [
        "# Note!\n",
        "Check hints in [Cheatsheet](https://colab.research.google.com/github/marcinsawinski/UEP_KIE_ML_CLASS/blob/main/00_cheatsheet.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xAqtuAQ_SXS"
      },
      "source": [
        "# Task 3.1\n",
        "_Get mnist data_\n",
        "\n",
        "```python\n",
        "from sklearn.datasets import fetch_openml\n",
        "mnist = fetch_openml('mnist_784', as_frame=False)\n",
        "```\n",
        "_Train simple model:_\n",
        "- Inspect dataset\n",
        "- Train binary Binary Classifier 5 or not 5 with SGDClassifier\n",
        "- Measure Accuracy Using Cross-Validation\n",
        "\n",
        "_Type your code below_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SMF3j7af_SXS"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "import numpy as np\n",
        "\n",
        "# Load MNIST\n",
        "mnist = fetch_openml(\"mnist_784\", as_frame=False)\n",
        "X = mnist.data\n",
        "y = mnist.target.astype(np.int8)\n",
        "\n",
        "# Create binary target: 1 if digit==5 else 0\n",
        "y_5 = (y == 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IPCdVURc_SXS"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "sgd_clf = SGDClassifier(random_state=42)\n",
        "accuracy_scores = cross_val_score(sgd_clf, X, y_5, cv=3, scoring=\"accuracy\")\n",
        "\n",
        "print(\"Cross-val accuracy:\", accuracy_scores)\n",
        "print(\"Mean accuracy:\", accuracy_scores.mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xXXkU7v_SXS"
      },
      "source": [
        "# Task 3.2\n",
        "_Check model results_\n",
        "- Check Confusion Matrix\n",
        "- Get Precision,  Recall and f1 score\n",
        "_Check Precision/Recall Trade-off_\n",
        "- Experiment with different threshold values\n",
        "- Calculate precision-recall curve and make precision-recall plot\n",
        "- Calculate ROC curve and make ROC curve plot\n",
        "- Calcuate ROC AUC score\n",
        "\n",
        "_Type your code below_"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
        "\n",
        "# Predictions from CV\n",
        "y_pred = cross_val_predict(sgd_clf, X, y_5, cv=3)\n",
        "\n",
        "print(\"Confusion matrix:\")\n",
        "print(confusion_matrix(y_5, y_pred))\n",
        "\n",
        "print(\"Precision:\", precision_score(y_5, y_pred))\n",
        "print(\"Recall:\", recall_score(y_5, y_pred))\n",
        "print(\"F1-score:\", f1_score(y_5, y_pred))"
      ],
      "metadata": {
        "id": "DRhE3FJm_vnQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_scores = cross_val_predict(\n",
        "    sgd_clf, X, y_5, cv=3, method=\"decision_function\"\n",
        ")"
      ],
      "metadata": {
        "id": "CR7OwEI_AGcz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_curve\n",
        "\n",
        "precisions, recalls, thresholds = precision_recall_curve(y_5, y_scores)\n",
        "\n",
        "print(\"Thresholds length:\", len(thresholds))\n",
        "print(\"Example threshold tuning: threshold=0\")\n",
        "y_pred_custom = (y_scores > 0)\n",
        "print(\"Precision:\", precision_score(y_5, y_pred_custom))\n",
        "print(\"Recall:\", recall_score(y_5, y_pred_custom))"
      ],
      "metadata": {
        "id": "hQAbJnL_AwHX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.plot(recalls, precisions)\n",
        "plt.xlabel(\"Recall\")\n",
        "plt.ylabel(\"Precision\")\n",
        "plt.title(\"Precision-Recall Curve\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YZUBgdvsA91K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "\n",
        "fpr, tpr, thresh = roc_curve(y_5, y_scores)\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.plot(fpr, tpr)\n",
        "plt.plot([0,1], [0,1], \"k--\")\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"ROC Curve\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "print(\"ROC AUC:\", roc_auc_score(y_5, y_scores))"
      ],
      "metadata": {
        "id": "gCsLKCvHBBG0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4d7NPlWy_SXS"
      },
      "source": [
        "# Task 3.3\n",
        "_Compare 2 models_\n",
        "- Train binary Binary Classifier 5 or not 5 with RandomForestClassifier\n",
        "- Compare results of  RandomForestClassifier with SGDClassifier usign precision-recall curve plot\n",
        "\n",
        "_Type your code below_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m9VC8WZn_SXS"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "\n",
        "rf_clf = RandomForestClassifier(\n",
        "    n_estimators=100,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Probabilities used instead of decision_function\n",
        "# y_scores_rf = p(class=1)\n",
        "y_scores_rf = cross_val_predict(\n",
        "    rf_clf,\n",
        "    X,\n",
        "    y_5,\n",
        "    cv=3,\n",
        "    method=\"predict_proba\"\n",
        ")[:, 1]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "sgd_clf = SGDClassifier(random_state=42)\n",
        "\n",
        "y_scores_sgd = cross_val_predict(\n",
        "    sgd_clf,\n",
        "    X,\n",
        "    y_5,\n",
        "    cv=3,\n",
        "    method=\"decision_function\"\n",
        ")"
      ],
      "metadata": {
        "id": "iJ6LI6PdBK-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_curve\n",
        "\n",
        "prec_sgd, rec_sgd, thr_sgd = precision_recall_curve(y_5, y_scores_sgd)\n",
        "prec_rf, rec_rf, thr_rf = precision_recall_curve(y_5, y_scores_rf)"
      ],
      "metadata": {
        "id": "NyuMhyRQBMoJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "\n",
        "plt.plot(rec_sgd, prec_sgd, label=\"SGDClassifier\", linewidth=2)\n",
        "plt.plot(rec_rf,  prec_rf,  label=\"RandomForestClassifier\", linewidth=2)\n",
        "\n",
        "plt.xlabel(\"Recall\")\n",
        "plt.ylabel(\"Precision\")\n",
        "plt.title(\"Precision-Recall Curve Comparison\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qGoBKnGCBNyO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehhj8OHe_SXS"
      },
      "source": [
        "# Task 3.4\n",
        "_Perform Multiclass Classification_\n",
        "- Train binary Multiclass Classifier (0-9) with Support Vector Classifier (SVC)\n",
        "\n",
        "_Error Analysis_\n",
        "- display multiclass Confusion Matrix\n",
        "- display multiclass Confusion Matrix normalized by row\n",
        "\n",
        "_Type your code below_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WByncCVL_SXS"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Optional: Subsample for performance (recommended)\n",
        "# Remove this block if you want full dataset\n",
        "X_small, _, y_small, _ = train_test_split(\n",
        "    X, y, test_size=0.85, random_state=42\n",
        ")\n",
        "\n",
        "svc_clf = SVC(kernel=\"rbf\", gamma=\"scale\")\n",
        "svc_clf.fit(X, y)\n",
        "\n",
        "print(\"Model trained.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "# Use part of the held-out data\n",
        "_, X_val, _, y_val = train_test_split(\n",
        "    X, y, test_size=0.15, random_state=42\n",
        ")\n",
        "\n",
        "y_pred_svc = svc_clf.predict(X_val)"
      ],
      "metadata": {
        "id": "SsI1re45OzjC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_val, y_pred_svc)\n",
        "cm"
      ],
      "metadata": {
        "id": "f4aC4G2-O1HU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "plt.figure(figsize=(10,8))\n",
        "plt.imshow(cm, cmap=\"Blues\")\n",
        "plt.title(\"Confusion Matrix (Counts)\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.colorbar()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iWNFi42rO1cN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm_norm = confusion_matrix(y_val, y_pred_svc, normalize=\"true\")\n",
        "\n",
        "plt.figure(figsize=(10,8))\n",
        "plt.imshow(cm_norm, cmap=\"Blues\")\n",
        "plt.title(\"Confusion Matrix (Normalized by Row)\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.colorbar()\n",
        "#plt.show()"
      ],
      "metadata": {
        "id": "pQDb9n7eZjRI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_M020Ny_SXS"
      },
      "source": [
        "# Task 3.5\n",
        " _Try to build a classifier for the MNIST dataset that achieves over 97% accuracy on the test set. Hint: the `KNeighborsClassifier` works quite well for this task; you just need to find good hyperparameter values (try a grid search on the `weights` and `n_neighbors` hyperparameters)._\n",
        "\n",
        " _Type your code below_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wa6pJ8iy_SXS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQQZ9rxs_SXS"
      },
      "source": [
        "# Task 3.6\n",
        "_Write a function that can shift an MNIST image in any direction (left, right, up, or down) by one pixel. You can use the `shift()` function from the `scipy.ndimage` module. For example, `shift(image, [2, 1], cval=0)` shifts the image two pixels down and one pixel to the right. Then, for each image in the training set, create four shifted copies (one per direction) and add them to the training set. Finally, train your best model on this expanded training set and measure its accuracy on the test set. You should observe that your model performs even better now! This technique of artificially growing the training set is called _data augmentation_ or _training set expansion_._\n",
        "\n",
        "\n",
        "_Type your code below_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zWmGlBZX_SXT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQeq25gY_SXT"
      },
      "source": [
        "# Task 3.7\n",
        "_Solve Titanic challenge on [Kaggle](https://www.kaggle.com/c/titanic). Alternatively, or get two CSV files: train.csv and test.csv  from :_\n",
        "```python\n",
        "url_titanic_train = 'https://github.com/marcinsawinski/UEP_KIE_ML_LAB_PROG/raw/main/datasets/titanic/train.csv'\n",
        "url_titanic_test = 'https://github.com/marcinsawinski/UEP_KIE_ML_LAB_PROG/raw/main/datasets/titanic/test.csv'\n",
        "```\n",
        "\n",
        " _The goal is to train a classifier that can predict the `Survived` column based on the other columns._"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i2ia2Vno_SXT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXJc_Jur_SXT"
      },
      "source": [
        "# Task 3.8\n",
        "\n",
        "_Build a spam classifier:_\n",
        "\n",
        "* _Download examples of spam and ham from [Apache SpamAssassin's public datasets](https://spamassassin.apache.org/old/publiccorpus/)._\n",
        "* _Unzip the datasets and familiarize yourself with the data format._\n",
        "* _Split the datasets into a training set and a test set._\n",
        "* _Write a data preparation pipeline to convert each email into a feature vector. Your preparation pipeline should transform an email into a (sparse) vector that indicates the presence or absence of each possible word. For example, if all emails only ever contain four words, \"Hello,\" \"how,\" \"are,\" \"you,\" then the email \"Hello you Hello Hello you\" would be converted into a vector [1, 0, 0, 1] (meaning [â€œHello\" is present, \"how\" is absent, \"are\" is absent, \"you\" is present]), or [3, 0, 0, 2] if you prefer to count the number of occurrences of each word._\n",
        "\n",
        "_You may want to add hyperparameters to your preparation pipeline to control whether or not to strip off email headers, convert each email to lowercase, remove punctuation, replace all URLs with \"URL,\" replace all numbers with \"NUMBER,\" or even perform _stemming_ (i.e., trim off word endings; there are Python libraries available to do this)._\n",
        "\n",
        "_Finally, try out several classifiers and see if you can build a spam classifier, with both high recall and high precision._"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SwjnLpRf_SXT"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.9.13 ('hml3')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13 | packaged by conda-forge | (main, May 27 2022, 17:01:00) \n[Clang 13.0.1 ]"
    },
    "nav_menu": {
      "height": "279px",
      "width": "309px"
    },
    "toc": {
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": "block",
      "toc_window_display": false
    },
    "vscode": {
      "interpreter": {
        "hash": "ac2598a53cd48ed973662853cbed9ce85601c819c2e7e5e54efa32ca245c1cee"
      }
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}